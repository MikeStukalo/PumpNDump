{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the scraped dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import pandas_datareader.data as web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the raw scraped datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_author</th>\n",
       "      <th>com_date</th>\n",
       "      <th>com_text</th>\n",
       "      <th>post_author</th>\n",
       "      <th>post_date</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuftybigfoot</td>\n",
       "      <td>2018-10-23T00:00:33+00:00</td>\n",
       "      <td>What about Canadian traders?</td>\n",
       "      <td>Al1Ge</td>\n",
       "      <td>2018-10-22T22:47:57+00:00</td>\n",
       "      <td>If so, what platform do you trade through?</td>\n",
       "      <td>Any UK based traders?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xTheHolyGhostx</td>\n",
       "      <td>2018-10-22T13:57:59+00:00</td>\n",
       "      <td>Very nice. I plan to hold onto my shares for a...</td>\n",
       "      <td>CaptainWeee</td>\n",
       "      <td>2018-10-22T13:34:50+00:00</td>\n",
       "      <td>Wow another article dropped today about us som...</td>\n",
       "      <td>$HIPH Another article released today with us i...</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mojaverae</td>\n",
       "      <td>2018-10-22T15:44:45+00:00</td>\n",
       "      <td>Big investors Sold on the news, took profits</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smooferated</td>\n",
       "      <td>2018-10-23T03:26:20+00:00</td>\n",
       "      <td>Always sell and take profits.  Especially when...</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jarsofmarsbarsincars</td>\n",
       "      <td>2018-10-22T16:29:45+00:00</td>\n",
       "      <td>People who invested at low prices pulled their...</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             com_author                   com_date  \\\n",
       "0          Tuftybigfoot  2018-10-23T00:00:33+00:00   \n",
       "1        xTheHolyGhostx  2018-10-22T13:57:59+00:00   \n",
       "2             Mojaverae  2018-10-22T15:44:45+00:00   \n",
       "3           smooferated  2018-10-23T03:26:20+00:00   \n",
       "4  jarsofmarsbarsincars  2018-10-22T16:29:45+00:00   \n",
       "\n",
       "                                            com_text  post_author  \\\n",
       "0                       What about Canadian traders?        Al1Ge   \n",
       "1  Very nice. I plan to hold onto my shares for a...  CaptainWeee   \n",
       "2       Big investors Sold on the news, took profits  vertical006   \n",
       "3  Always sell and take profits.  Especially when...  vertical006   \n",
       "4  People who invested at low prices pulled their...  vertical006   \n",
       "\n",
       "                   post_date  \\\n",
       "0  2018-10-22T22:47:57+00:00   \n",
       "1  2018-10-22T13:34:50+00:00   \n",
       "2  2018-10-22T15:43:23+00:00   \n",
       "3  2018-10-22T15:43:23+00:00   \n",
       "4  2018-10-22T15:43:23+00:00   \n",
       "\n",
       "                                           post_text  \\\n",
       "0         If so, what platform do you trade through?   \n",
       "1  Wow another article dropped today about us som...   \n",
       "2  I picked up a few stocks months before Canada ...   \n",
       "3  I picked up a few stocks months before Canada ...   \n",
       "4  I picked up a few stocks months before Canada ...   \n",
       "\n",
       "                                          post_title  \\\n",
       "0                              Any UK based traders?   \n",
       "1  $HIPH Another article released today with us i...   \n",
       "2    What's going on with Canadian marijuana stocks?   \n",
       "3    What's going on with Canadian marijuana stocks?   \n",
       "4    What's going on with Canadian marijuana stocks?   \n",
       "\n",
       "                                            post_url  \n",
       "0  https://old.reddit.com/r/pennystocks/comments/...  \n",
       "1  https://old.reddit.com/r/pennystocks/comments/...  \n",
       "2  https://old.reddit.com/r/pennystocks/comments/...  \n",
       "3  https://old.reddit.com/r/pennystocks/comments/...  \n",
       "4  https://old.reddit.com/r/pennystocks/comments/...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penny_stock = pd.read_csv(\"data/penny_stocks.csv\", parse_dates=True)\n",
    "penny_stock.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_author</th>\n",
       "      <th>com_date</th>\n",
       "      <th>com_text</th>\n",
       "      <th>post_author</th>\n",
       "      <th>post_date</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weredagabagool</td>\n",
       "      <td>2018-10-23T14:59:06+00:00</td>\n",
       "      <td>This sub is kryptonite to every single stock m...</td>\n",
       "      <td>Vigamoxx</td>\n",
       "      <td>2018-10-23T14:01:50+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFMK shooting up!!</td>\n",
       "      <td>https://old.reddit.com/r/RobinHoodPennyStocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>julbjulb</td>\n",
       "      <td>2018-10-23T14:05:06+00:00</td>\n",
       "      <td>You had to jinx it lol</td>\n",
       "      <td>Vigamoxx</td>\n",
       "      <td>2018-10-23T14:01:50+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFMK shooting up!!</td>\n",
       "      <td>https://old.reddit.com/r/RobinHoodPennyStocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vigamoxx</td>\n",
       "      <td>2018-10-23T14:06:36+00:00</td>\n",
       "      <td>Yeah I bought at $2.01 at 9:58, at 10:00 it wa...</td>\n",
       "      <td>Vigamoxx</td>\n",
       "      <td>2018-10-23T14:01:50+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFMK shooting up!!</td>\n",
       "      <td>https://old.reddit.com/r/RobinHoodPennyStocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>julbjulb</td>\n",
       "      <td>2018-10-23T14:54:27+00:00</td>\n",
       "      <td>ðŸ“ˆ gl</td>\n",
       "      <td>Vigamoxx</td>\n",
       "      <td>2018-10-23T14:01:50+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFMK shooting up!!</td>\n",
       "      <td>https://old.reddit.com/r/RobinHoodPennyStocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joesmithers</td>\n",
       "      <td>2018-10-22T23:23:10+00:00</td>\n",
       "      <td>My immediate goal is to get above $25,000 so I...</td>\n",
       "      <td>Joesmithers</td>\n",
       "      <td>2018-10-22T23:17:17+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rate my meme portfolio</td>\n",
       "      <td>https://old.reddit.com/r/RobinHoodPennyStocks/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       com_author                   com_date  \\\n",
       "0  weredagabagool  2018-10-23T14:59:06+00:00   \n",
       "1        julbjulb  2018-10-23T14:05:06+00:00   \n",
       "2        Vigamoxx  2018-10-23T14:06:36+00:00   \n",
       "3        julbjulb  2018-10-23T14:54:27+00:00   \n",
       "4     Joesmithers  2018-10-22T23:23:10+00:00   \n",
       "\n",
       "                                            com_text  post_author  \\\n",
       "0  This sub is kryptonite to every single stock m...     Vigamoxx   \n",
       "1                             You had to jinx it lol     Vigamoxx   \n",
       "2  Yeah I bought at $2.01 at 9:58, at 10:00 it wa...     Vigamoxx   \n",
       "3                                               ðŸ“ˆ gl     Vigamoxx   \n",
       "4  My immediate goal is to get above $25,000 so I...  Joesmithers   \n",
       "\n",
       "                   post_date post_text              post_title  \\\n",
       "0  2018-10-23T14:01:50+00:00       NaN      IFMK shooting up!!   \n",
       "1  2018-10-23T14:01:50+00:00       NaN      IFMK shooting up!!   \n",
       "2  2018-10-23T14:01:50+00:00       NaN      IFMK shooting up!!   \n",
       "3  2018-10-23T14:01:50+00:00       NaN      IFMK shooting up!!   \n",
       "4  2018-10-22T23:17:17+00:00       NaN  Rate my meme portfolio   \n",
       "\n",
       "                                            post_url  \n",
       "0  https://old.reddit.com/r/RobinHoodPennyStocks/...  \n",
       "1  https://old.reddit.com/r/RobinHoodPennyStocks/...  \n",
       "2  https://old.reddit.com/r/RobinHoodPennyStocks/...  \n",
       "3  https://old.reddit.com/r/RobinHoodPennyStocks/...  \n",
       "4  https://old.reddit.com/r/RobinHoodPennyStocks/...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robin = pd.read_csv(\"data/robin.csv\", parse_dates=True)\n",
    "robin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_author</th>\n",
       "      <th>com_date</th>\n",
       "      <th>com_text</th>\n",
       "      <th>post_author</th>\n",
       "      <th>post_date</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_url</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuftybigfoot</td>\n",
       "      <td>2018-10-23T00:00:33+00:00</td>\n",
       "      <td>What about Canadian traders?</td>\n",
       "      <td>Al1Ge</td>\n",
       "      <td>2018-10-22T22:47:57+00:00</td>\n",
       "      <td>If so, what platform do you trade through?</td>\n",
       "      <td>Any UK based traders?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xTheHolyGhostx</td>\n",
       "      <td>2018-10-22T13:57:59+00:00</td>\n",
       "      <td>Very nice. I plan to hold onto my shares for a...</td>\n",
       "      <td>CaptainWeee</td>\n",
       "      <td>2018-10-22T13:34:50+00:00</td>\n",
       "      <td>Wow another article dropped today about us som...</td>\n",
       "      <td>$HIPH Another article released today with us i...</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mojaverae</td>\n",
       "      <td>2018-10-22T15:44:45+00:00</td>\n",
       "      <td>Big investors Sold on the news, took profits</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smooferated</td>\n",
       "      <td>2018-10-23T03:26:20+00:00</td>\n",
       "      <td>Always sell and take profits.  Especially when...</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jarsofmarsbarsincars</td>\n",
       "      <td>2018-10-22T16:29:45+00:00</td>\n",
       "      <td>People who invested at low prices pulled their...</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             com_author                   com_date  \\\n",
       "0          Tuftybigfoot  2018-10-23T00:00:33+00:00   \n",
       "1        xTheHolyGhostx  2018-10-22T13:57:59+00:00   \n",
       "2             Mojaverae  2018-10-22T15:44:45+00:00   \n",
       "3           smooferated  2018-10-23T03:26:20+00:00   \n",
       "4  jarsofmarsbarsincars  2018-10-22T16:29:45+00:00   \n",
       "\n",
       "                                            com_text  post_author  \\\n",
       "0                       What about Canadian traders?        Al1Ge   \n",
       "1  Very nice. I plan to hold onto my shares for a...  CaptainWeee   \n",
       "2       Big investors Sold on the news, took profits  vertical006   \n",
       "3  Always sell and take profits.  Especially when...  vertical006   \n",
       "4  People who invested at low prices pulled their...  vertical006   \n",
       "\n",
       "                   post_date  \\\n",
       "0  2018-10-22T22:47:57+00:00   \n",
       "1  2018-10-22T13:34:50+00:00   \n",
       "2  2018-10-22T15:43:23+00:00   \n",
       "3  2018-10-22T15:43:23+00:00   \n",
       "4  2018-10-22T15:43:23+00:00   \n",
       "\n",
       "                                           post_text  \\\n",
       "0         If so, what platform do you trade through?   \n",
       "1  Wow another article dropped today about us som...   \n",
       "2  I picked up a few stocks months before Canada ...   \n",
       "3  I picked up a few stocks months before Canada ...   \n",
       "4  I picked up a few stocks months before Canada ...   \n",
       "\n",
       "                                          post_title  \\\n",
       "0                              Any UK based traders?   \n",
       "1  $HIPH Another article released today with us i...   \n",
       "2    What's going on with Canadian marijuana stocks?   \n",
       "3    What's going on with Canadian marijuana stocks?   \n",
       "4    What's going on with Canadian marijuana stocks?   \n",
       "\n",
       "                                            post_url       subreddit  \n",
       "0  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks  \n",
       "1  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks  \n",
       "2  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks  \n",
       "3  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks  \n",
       "4  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set flags for the subreddit\n",
    "penny_stock['subreddit'] = '/r/pennystocks'\n",
    "robin['subreddit'] = '/r/RobinHoodPennyStocks'\n",
    "\n",
    "# Combine two datasets\n",
    "penny = penny_stock.append(robin, ignore_index=True)\n",
    "penny.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Find unique tickers mentioned in posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find unique company tickers. The result is pickled for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all textual info\n",
    "all_text = penny['post_text'] + penny['com_text'] + penny['post_title'] \n",
    "all_text = all_text.dropna().astype(str)\n",
    "all_text = \" \".join(all_text)\n",
    "\n",
    "# Get unique stocks in a form $TCKR\n",
    "set1 = re.findall(pattern='\\$[A-Z]{2,4}', string = all_text)\n",
    "set1 = list(map(lambda x: x.replace(\"$\",\"\"), set1))\n",
    "set1 = set(set1)\n",
    "\n",
    "# Get unique stocks in the form NASDAQ:TCKR\n",
    "set2 = re.findall(pattern='NASDA.:[A-Z]{2,4}', string = all_text)\n",
    "set2 = list(map(lambda x: x.replace(\"NASDAQ:\",\"\"), set1))\n",
    "set2 = set(set2)\n",
    "\n",
    "# Combine both\n",
    "tickers = [*set1] + [*set2]\n",
    "\n",
    "# Write tickers to a file\n",
    "with open('./tmp/tickers', 'wb') as fp:\n",
    "    pickle.dump(tickers, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Find unique tickers for penny stocks and download quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 'pickled' tickers extracted from the scraped dataset and try downloading stock prices data from Yahoo Finance.\n",
    "\n",
    "Some of the stocks that are traded on non-US exchanges may have additional suffixes to the ticker on Yahoo Finance. In this case this code will not obtain the stock quotes and we drop observations. It can be manually or semi-atudomatically fixed in the future research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tmp/tickers', 'rb') as fp:\n",
    "    tickers = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This code takes a while to run. You can use the csv file below instead of downloading quotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRLY is missing\n",
      "obtained CCCL (207, 6)\n",
      "obtained HEME (207, 6)\n",
      "obtained SCYX (207, 6)\n",
      "obtained GALT (207, 6)\n",
      "obtained MO (207, 6)\n",
      "BRLX is missing\n",
      "obtained WM (207, 6)\n",
      "obtained SGYP (207, 6)\n",
      "obtained RSHN (205, 6)\n",
      "obtained OGEN (207, 6)\n",
      "obtained TSLA (207, 6)\n",
      "obtained DTEA (207, 6)\n",
      "obtained ISBG (207, 6)\n",
      "obtained LCLP (207, 6)\n",
      "obtained SPRO (207, 6)\n",
      "RQFT is missing\n",
      "obtained BE (106, 6)\n",
      "obtained BLPG (207, 6)\n",
      "BIOA is missing\n",
      "obtained CFGX (207, 6)\n",
      "obtained CGC (199, 6)\n",
      "obtained KO (207, 6)\n",
      "obtained TLRY (68, 6)\n",
      "obtained ETST (207, 6)\n",
      "obtained PKG (207, 6)\n",
      "obtained VTVT (207, 6)\n",
      "JUGR is missing\n",
      "BRVR is missing\n",
      "obtained QQQ (207, 6)\n",
      "obtained BB (207, 6)\n",
      "obtained BLNK (207, 6)\n",
      "obtained BLPH (207, 6)\n",
      "obtained CRMD (207, 6)\n",
      "BEER is missing\n",
      "obtained GLOW (198, 6)\n",
      "obtained STNN (207, 6)\n",
      "RNKL is missing\n",
      "obtained PACB (207, 6)\n",
      "obtained JCP (207, 6)\n",
      "obtained APRN (207, 6)\n",
      "obtained EVSV (207, 6)\n",
      "obtained ITRO (207, 6)\n",
      "SPLI is missing\n",
      "ROPE is missing\n",
      "obtained MOSY (207, 6)\n",
      "obtained ACRX (207, 6)\n",
      "obtained SSFT (207, 6)\n",
      "obtained SWRM (207, 6)\n",
      "obtained MJNE (207, 6)\n",
      "obtained HMNY (207, 6)\n",
      "obtained TTPH (207, 6)\n",
      "obtained AMAT (207, 6)\n",
      "obtained PPCB (207, 6)\n",
      "obtained TTNP (207, 6)\n",
      "obtained DLR (207, 6)\n",
      "obtained PAVM (207, 6)\n",
      "obtained INTK (207, 6)\n",
      "obtained MBII (207, 6)\n",
      "obtained NTLK (207, 6)\n",
      "obtained OHRP (207, 6)\n",
      "obtained HUTN (207, 6)\n",
      "obtained QSHI (10, 6)\n",
      "obtained XYF (27, 6)\n",
      "PTNY is missing\n",
      "obtained RISE (207, 6)\n",
      "obtained ATPT (207, 6)\n",
      "obtained ROP (207, 6)\n",
      "obtained VAPE (207, 6)\n",
      "obtained ATRS (207, 6)\n",
      "obtained NUGL (207, 6)\n",
      "obtained ALT (207, 6)\n",
      "obtained AMMA (207, 6)\n",
      "obtained CIFS (207, 6)\n",
      "TGV is missing\n",
      "obtained CANB (207, 6)\n",
      "obtained BCCI (207, 6)\n",
      "obtained AREB (146, 6)\n",
      "obtained IGC (207, 6)\n",
      "obtained ICTV (207, 6)\n",
      "obtained AVGO (207, 6)\n",
      "obtained GRNH (207, 6)\n",
      "obtained AGRX (207, 6)\n",
      "obtained CRON (169, 6)\n",
      "obtained RKDA (207, 6)\n",
      "VTLW is missing\n",
      "obtained MLHC (206, 6)\n",
      "obtained DCIX (207, 6)\n",
      "obtained PLX (207, 6)\n",
      "obtained GSS (207, 6)\n",
      "obtained RGSE (207, 6)\n",
      "obtained TNTY (207, 6)\n",
      "obtained NHPI (207, 6)\n",
      "obtained AVEO (207, 6)\n",
      "obtained SECI (206, 6)\n",
      "obtained SIPC (207, 6)\n",
      "obtained CWBR (207, 6)\n",
      "obtained ATNM (207, 6)\n",
      "AMDE is missing\n",
      "obtained AKER (207, 6)\n",
      "obtained AMFE (207, 6)\n",
      "obtained PED (207, 6)\n",
      "obtained SSKN (207, 6)\n",
      "obtained BVTK (207, 6)\n",
      "obtained BYOC (207, 6)\n",
      "obtained XXII (207, 6)\n",
      "obtained ASM (207, 6)\n",
      "obtained ACAD (207, 6)\n",
      "BLON is missing\n",
      "obtained MU (207, 6)\n",
      "obtained MCIG (207, 6)\n",
      "obtained FIZZ (207, 6)\n",
      "obtained INND (207, 6)\n",
      "obtained EOMN (207, 6)\n",
      "obtained CLDX (207, 6)\n",
      "obtained ACB (24, 6)\n",
      "INMG is missing\n",
      "obtained FCEL (207, 6)\n",
      "obtained GRDO (207, 6)\n",
      "obtained NPHC (207, 6)\n",
      "obtained NBRV (207, 6)\n",
      "obtained COLL (207, 6)\n",
      "obtained CCIH (207, 6)\n",
      "obtained MCOA (207, 6)\n",
      "ALN is missing\n",
      "obtained CHEK (207, 6)\n",
      "obtained NVCN (207, 6)\n",
      "obtained INTV (207, 6)\n",
      "obtained SGMD (207, 6)\n",
      "ACBF is missing\n",
      "obtained CGRW (207, 6)\n",
      "obtained SQ (207, 6)\n",
      "obtained ENPH (207, 6)\n",
      "RBIZ is missing\n",
      "obtained UBQU (207, 6)\n",
      "obtained AMPE (207, 6)\n",
      "obtained TRXC (207, 6)\n",
      "obtained SING (207, 6)\n",
      "obtained AKAO (207, 6)\n",
      "obtained SGTN (207, 6)\n",
      "obtained INPX (207, 6)\n",
      "PNO is missing\n",
      "obtained BPMX (207, 6)\n",
      "obtained SNGX (207, 6)\n",
      "SLSB is missing\n",
      "obtained TGLO (207, 6)\n",
      "obtained AZFL (206, 6)\n",
      "RNX is missing\n",
      "obtained APHB (207, 6)\n",
      "obtained LEVB (207, 6)\n",
      "obtained APTO (207, 6)\n",
      "obtained SYN (207, 6)\n",
      "obtained BPTH (207, 6)\n",
      "obtained EXPL (206, 6)\n",
      "obtained DEO (207, 6)\n",
      "obtained MYSZ (207, 6)\n",
      "obtained RDGL (207, 6)\n",
      "obtained AKG (207, 6)\n",
      "obtained ONCS (207, 6)\n",
      "obtained WEYL (204, 6)\n",
      "obtained SDPI (207, 6)\n",
      "NF is missing\n",
      "obtained HAIR (207, 6)\n",
      "obtained PRTK (207, 6)\n",
      "obtained MPIX (206, 6)\n",
      "obtained ECMT (206, 6)\n",
      "obtained CSCO (207, 6)\n",
      "obtained LDSR (207, 6)\n",
      "PNIS is missing\n",
      "obtained OHGI (207, 6)\n",
      "obtained NEPT (207, 6)\n",
      "obtained AMRN (207, 6)\n",
      "obtained OWCP (207, 6)\n",
      "obtained AMD (207, 6)\n",
      "obtained ABIO (207, 6)\n",
      "HEXO is missing\n",
      "obtained ARQL (207, 6)\n",
      "obtained DRUS (207, 6)\n",
      "obtained GNCA (207, 6)\n",
      "obtained GEVO (207, 6)\n",
      "CEMP is missing\n",
      "obtained SPY (207, 6)\n",
      "obtained PMDL (29, 6)\n",
      "obtained APH (207, 6)\n",
      "obtained EARS (207, 6)\n",
      "obtained RWLK (207, 6)\n",
      "obtained HSGX (207, 6)\n",
      "obtained YECO (207, 6)\n",
      "MJB is missing\n",
      "obtained SSLJ (181, 6)\n",
      "obtained MTNB (207, 6)\n",
      "obtained DIRV (207, 6)\n",
      "RZPK is missing\n",
      "obtained WDDD (207, 6)\n",
      "ICNA is missing\n",
      "obtained POTN (207, 6)\n",
      "obtained PVCT (207, 6)\n",
      "obtained SAGE (207, 6)\n",
      "obtained MDGL (207, 6)\n",
      "obtained ZNGA (207, 6)\n",
      "obtained NGD (207, 6)\n",
      "obtained LODE (207, 6)\n",
      "obtained AMDA (207, 6)\n",
      "obtained IMNP (207, 6)\n",
      "obtained PULM (207, 6)\n",
      "obtained SRPT (207, 6)\n",
      "obtained SLDB (188, 6)\n",
      "obtained CVSI (207, 6)\n",
      "RHMB is missing\n",
      "obtained CZNI (18, 6)\n",
      "EMC is missing\n",
      "obtained KOOL (207, 6)\n",
      "obtained ANDI (207, 6)\n",
      "obtained HIPH (207, 6)\n",
      "obtained RCGP (207, 6)\n",
      "obtained KGKG (207, 6)\n",
      "obtained PHIL (207, 6)\n",
      "obtained FPAY (207, 6)\n",
      "obtained RIGL (207, 6)\n",
      "obtained NIO (32, 6)\n",
      "EGLX is missing\n",
      "obtained BDCI (207, 6)\n",
      "ACBB is missing\n",
      "obtained CPHI (207, 6)\n",
      "ATE is missing\n",
      "obtained MNGA (207, 6)\n",
      "obtained SPCL (191, 6)\n",
      "obtained ABBV (207, 6)\n",
      "obtained RHE (207, 6)\n",
      "obtained PTI (207, 6)\n",
      "OCRX is missing\n",
      "obtained NAVB (207, 6)\n",
      "obtained SNAP (207, 6)\n",
      "obtained ANY (207, 6)\n",
      "obtained HEMP (207, 6)\n",
      "obtained CEI (207, 6)\n",
      "obtained SAGD (207, 6)\n",
      "obtained AQB (207, 6)\n",
      "obtained SMRT (207, 6)\n",
      "obtained NLST (207, 6)\n",
      "obtained GTBP (205, 6)\n",
      "obtained APTY (207, 6)\n",
      "obtained HUGE (207, 6)\n",
      "obtained ABEV (207, 6)\n",
      "obtained NBEV (207, 6)\n",
      "ACOL is missing\n",
      "obtained PTIE (207, 6)\n",
      "obtained JONE (207, 6)\n",
      "obtained FNCX (207, 6)\n",
      "obtained HLIX (207, 6)\n",
      "obtained TOPS (207, 6)\n",
      "obtained VTL (207, 6)\n",
      "obtained VSTM (207, 6)\n",
      "obtained MLNT (207, 6)\n",
      "obtained ATRX (13, 6)\n",
      "obtained JNJ (207, 6)\n",
      "obtained CBL (207, 6)\n",
      "obtained DIS (207, 6)\n",
      "obtained MLTC (206, 6)\n",
      "obtained JMU (207, 6)\n",
      "obtained PLUG (207, 6)\n",
      "obtained VTGN (207, 6)\n",
      "obtained DFFN (207, 6)\n",
      "obtained BORN (198, 6)\n",
      "obtained TRVN (207, 6)\n",
      "WEED is missing\n",
      "obtained BWVI (207, 6)\n",
      "obtained PYTG (207, 6)\n",
      "obtained JAGX (207, 6)\n",
      "obtained MJ (207, 6)\n",
      "obtained CDTX (207, 6)\n",
      "obtained AMRS (207, 6)\n",
      "obtained CFRX (207, 6)\n",
      "obtained TRUL (207, 6)\n",
      "obtained PURA (207, 6)\n",
      "obtained PRPO (207, 6)\n",
      "obtained TLRA (207, 6)\n",
      "obtained HUSA (207, 6)\n",
      "obtained CDIX (207, 6)\n",
      "obtained SEED (207, 6)\n",
      "IFMX is missing\n",
      "obtained GERN (207, 6)\n",
      "WMDC is missing\n",
      "obtained LITH (207, 6)\n",
      "obtained SNSS (207, 6)\n",
      "obtained ICAN (207, 6)\n",
      "obtained NSPR (207, 6)\n",
      "obtained VKTX (207, 6)\n",
      "obtained SSOF (207, 6)\n",
      "obtained DRYS (207, 6)\n",
      "RSGE is missing\n",
      "obtained MRNS (207, 6)\n",
      "TRLY is missing\n",
      "obtained HEME (207, 6)\n",
      "obtained CCCL (207, 6)\n",
      "obtained SCYX (207, 6)\n",
      "obtained GALT (207, 6)\n",
      "obtained MO (207, 6)\n",
      "BRLX is missing\n",
      "obtained WM (207, 6)\n",
      "obtained SGYP (207, 6)\n",
      "obtained RSHN (205, 6)\n",
      "obtained OGEN (207, 6)\n",
      "obtained TSLA (207, 6)\n",
      "obtained DTEA (207, 6)\n",
      "obtained SPRO (207, 6)\n",
      "obtained ISBG (207, 6)\n",
      "obtained LCLP (207, 6)\n",
      "RQFT is missing\n",
      "obtained BE (106, 6)\n",
      "BIOA is missing\n",
      "obtained BLPG (207, 6)\n",
      "obtained CFGX (207, 6)\n",
      "obtained CGC (199, 6)\n",
      "obtained KO (207, 6)\n",
      "obtained TLRY (68, 6)\n",
      "obtained ETST (207, 6)\n",
      "obtained PKG (207, 6)\n",
      "obtained VTVT (207, 6)\n",
      "JUGR is missing\n",
      "BRVR is missing\n",
      "obtained QQQ (207, 6)\n",
      "obtained BB (207, 6)\n",
      "obtained BLNK (207, 6)\n",
      "obtained BLPH (207, 6)\n",
      "obtained CRMD (207, 6)\n",
      "BEER is missing\n",
      "obtained GLOW (198, 6)\n",
      "obtained STNN (207, 6)\n",
      "RNKL is missing\n",
      "obtained PACB (207, 6)\n",
      "obtained JCP (207, 6)\n",
      "obtained APRN (207, 6)\n",
      "obtained EVSV (207, 6)\n",
      "obtained ITRO (207, 6)\n",
      "SPLI is missing\n",
      "ROPE is missing\n",
      "obtained MOSY (207, 6)\n",
      "obtained ACRX (207, 6)\n",
      "obtained SSFT (207, 6)\n",
      "obtained SWRM (207, 6)\n",
      "obtained MJNE (207, 6)\n",
      "obtained HMNY (207, 6)\n",
      "obtained TTPH (207, 6)\n",
      "obtained AMAT (207, 6)\n",
      "obtained PPCB (207, 6)\n",
      "obtained TTNP (207, 6)\n",
      "obtained DLR (207, 6)\n",
      "obtained PAVM (207, 6)\n",
      "obtained INTK (207, 6)\n",
      "obtained MBII (207, 6)\n",
      "obtained NTLK (207, 6)\n",
      "obtained HUTN (207, 6)\n",
      "obtained OHRP (207, 6)\n",
      "obtained QSHI (10, 6)\n",
      "obtained XYF (27, 6)\n",
      "PTNY is missing\n",
      "obtained RISE (207, 6)\n",
      "obtained ATPT (207, 6)\n",
      "obtained ROP (207, 6)\n",
      "obtained VAPE (207, 6)\n",
      "obtained ATRS (207, 6)\n",
      "obtained NUGL (207, 6)\n",
      "obtained ALT (207, 6)\n",
      "obtained AMMA (207, 6)\n",
      "obtained CIFS (207, 6)\n",
      "obtained CANB (207, 6)\n",
      "obtained BCCI (207, 6)\n",
      "TGV is missing\n",
      "obtained AREB (146, 6)\n",
      "obtained IGC (207, 6)\n",
      "obtained AVGO (207, 6)\n",
      "obtained ICTV (207, 6)\n",
      "obtained DRYS (207, 6)\n",
      "obtained AGRX (207, 6)\n",
      "obtained CRON (169, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtained RKDA (207, 6)\n",
      "VTLW is missing\n",
      "obtained MLHC (206, 6)\n",
      "obtained DCIX (207, 6)\n",
      "obtained PLX (207, 6)\n",
      "obtained GSS (207, 6)\n",
      "obtained RGSE (207, 6)\n",
      "obtained TNTY (207, 6)\n",
      "obtained NHPI (207, 6)\n",
      "obtained AVEO (207, 6)\n",
      "obtained SECI (206, 6)\n",
      "obtained SIPC (207, 6)\n",
      "obtained CWBR (207, 6)\n",
      "obtained ATNM (207, 6)\n",
      "AMDE is missing\n",
      "obtained AKER (207, 6)\n",
      "obtained AMFE (207, 6)\n",
      "obtained PED (207, 6)\n",
      "obtained SSKN (207, 6)\n",
      "obtained BVTK (207, 6)\n",
      "obtained BYOC (207, 6)\n",
      "obtained XXII (207, 6)\n",
      "obtained ASM (207, 6)\n",
      "obtained ACAD (207, 6)\n",
      "obtained SSOF (207, 6)\n",
      "BLON is missing\n",
      "obtained MU (207, 6)\n",
      "obtained MCIG (207, 6)\n",
      "obtained FIZZ (207, 6)\n",
      "obtained INND (207, 6)\n",
      "obtained EOMN (207, 6)\n",
      "obtained CLDX (207, 6)\n",
      "obtained ACB (24, 6)\n",
      "INMG is missing\n",
      "obtained FCEL (207, 6)\n",
      "obtained GRDO (207, 6)\n",
      "obtained NPHC (207, 6)\n",
      "obtained NBRV (207, 6)\n",
      "obtained COLL (207, 6)\n",
      "obtained CCIH (207, 6)\n",
      "obtained MCOA (207, 6)\n",
      "ALN is missing\n",
      "obtained CHEK (207, 6)\n",
      "obtained NVCN (207, 6)\n",
      "obtained INTV (207, 6)\n",
      "obtained SGMD (207, 6)\n",
      "ACBF is missing\n",
      "obtained CGRW (207, 6)\n",
      "obtained SQ (207, 6)\n",
      "obtained ENPH (207, 6)\n",
      "RBIZ is missing\n",
      "obtained UBQU (207, 6)\n",
      "obtained AMPE (207, 6)\n",
      "obtained TRXC (207, 6)\n",
      "obtained SING (207, 6)\n",
      "obtained AKAO (207, 6)\n",
      "obtained SGTN (207, 6)\n",
      "obtained INPX (207, 6)\n",
      "PNO is missing\n",
      "obtained BPMX (207, 6)\n",
      "SLSB is missing\n",
      "obtained TGLO (207, 6)\n",
      "obtained AZFL (206, 6)\n",
      "RNX is missing\n",
      "obtained APHB (207, 6)\n",
      "obtained LEVB (207, 6)\n",
      "obtained APTO (207, 6)\n",
      "obtained SYN (207, 6)\n",
      "obtained BPTH (207, 6)\n",
      "obtained EXPL (206, 6)\n",
      "obtained DEO (207, 6)\n",
      "obtained MYSZ (207, 6)\n",
      "obtained RDGL (207, 6)\n",
      "obtained AKG (207, 6)\n",
      "obtained ONCS (207, 6)\n",
      "obtained WEYL (204, 6)\n",
      "obtained SDPI (207, 6)\n",
      "NF is missing\n",
      "obtained HAIR (207, 6)\n",
      "obtained PRTK (207, 6)\n",
      "obtained MPIX (206, 6)\n",
      "obtained ECMT (206, 6)\n",
      "obtained CSCO (207, 6)\n",
      "obtained LDSR (207, 6)\n",
      "PNIS is missing\n",
      "obtained OHGI (207, 6)\n",
      "obtained NEPT (207, 6)\n",
      "obtained AMRN (207, 6)\n",
      "obtained OWCP (207, 6)\n",
      "obtained AMD (207, 6)\n",
      "obtained ABIO (207, 6)\n",
      "HEXO is missing\n",
      "obtained ARQL (207, 6)\n",
      "obtained DRUS (207, 6)\n",
      "obtained GNCA (207, 6)\n",
      "obtained GEVO (207, 6)\n",
      "CEMP is missing\n",
      "obtained SPY (207, 6)\n",
      "obtained PMDL (29, 6)\n",
      "obtained APH (207, 6)\n",
      "obtained EARS (207, 6)\n",
      "obtained RWLK (207, 6)\n",
      "obtained HSGX (207, 6)\n",
      "obtained YECO (207, 6)\n",
      "MJB is missing\n",
      "obtained SSLJ (181, 6)\n",
      "obtained MTNB (207, 6)\n",
      "obtained DIRV (207, 6)\n",
      "RZPK is missing\n",
      "obtained WDDD (207, 6)\n",
      "ICNA is missing\n",
      "obtained POTN (207, 6)\n",
      "obtained PVCT (207, 6)\n",
      "obtained SAGE (207, 6)\n",
      "obtained MDGL (207, 6)\n",
      "obtained ZNGA (207, 6)\n",
      "obtained NGD (207, 6)\n",
      "obtained LODE (207, 6)\n",
      "obtained AMDA (207, 6)\n",
      "obtained IMNP (207, 6)\n",
      "obtained PULM (207, 6)\n",
      "obtained SRPT (207, 6)\n",
      "obtained SLDB (188, 6)\n",
      "obtained CVSI (207, 6)\n",
      "RHMB is missing\n",
      "obtained CZNI (18, 6)\n",
      "EMC is missing\n",
      "obtained KOOL (207, 6)\n",
      "obtained ANDI (207, 6)\n",
      "obtained HIPH (207, 6)\n",
      "obtained RCGP (207, 6)\n",
      "obtained KGKG (207, 6)\n",
      "obtained PHIL (207, 6)\n",
      "obtained FPAY (207, 6)\n",
      "obtained RIGL (207, 6)\n",
      "obtained NIO (32, 6)\n",
      "EGLX is missing\n",
      "obtained BDCI (207, 6)\n",
      "ACBB is missing\n",
      "obtained CPHI (207, 6)\n",
      "ATE is missing\n",
      "obtained MNGA (207, 6)\n",
      "obtained SPCL (191, 6)\n",
      "obtained ABBV (207, 6)\n",
      "obtained RHE (207, 6)\n",
      "obtained PTI (207, 6)\n",
      "OCRX is missing\n",
      "obtained NAVB (207, 6)\n",
      "obtained SNAP (207, 6)\n",
      "obtained ANY (207, 6)\n",
      "obtained HEMP (207, 6)\n",
      "obtained CEI (207, 6)\n",
      "obtained SAGD (207, 6)\n",
      "obtained AQB (207, 6)\n",
      "obtained SMRT (207, 6)\n",
      "obtained NLST (207, 6)\n",
      "obtained GTBP (205, 6)\n",
      "obtained APTY (207, 6)\n",
      "obtained HUGE (207, 6)\n",
      "obtained ABEV (207, 6)\n",
      "obtained NBEV (207, 6)\n",
      "ACOL is missing\n",
      "obtained PTIE (207, 6)\n",
      "obtained JONE (207, 6)\n",
      "obtained FNCX (207, 6)\n",
      "obtained HLIX (207, 6)\n",
      "obtained TOPS (207, 6)\n",
      "obtained VTL (207, 6)\n",
      "obtained VSTM (207, 6)\n",
      "obtained MLNT (207, 6)\n",
      "obtained ATRX (13, 6)\n",
      "obtained JNJ (207, 6)\n",
      "obtained CBL (207, 6)\n",
      "obtained DIS (207, 6)\n",
      "obtained MLTC (206, 6)\n",
      "obtained JMU (207, 6)\n",
      "obtained PLUG (207, 6)\n",
      "obtained VTGN (207, 6)\n",
      "obtained DFFN (207, 6)\n",
      "obtained BORN (198, 6)\n",
      "obtained TRVN (207, 6)\n",
      "WEED is missing\n",
      "obtained BWVI (207, 6)\n",
      "obtained PYTG (207, 6)\n",
      "obtained JAGX (207, 6)\n",
      "obtained MJ (207, 6)\n",
      "obtained CDTX (207, 6)\n",
      "obtained AMRS (207, 6)\n",
      "obtained CFRX (207, 6)\n",
      "obtained TRUL (207, 6)\n",
      "obtained PURA (207, 6)\n",
      "obtained PRPO (207, 6)\n",
      "obtained TLRA (207, 6)\n",
      "obtained HUSA (207, 6)\n",
      "obtained CDIX (207, 6)\n",
      "obtained SEED (207, 6)\n",
      "IFMX is missing\n",
      "obtained GERN (207, 6)\n",
      "WMDC is missing\n",
      "obtained LITH (207, 6)\n",
      "obtained SNSS (207, 6)\n",
      "obtained ICAN (207, 6)\n",
      "obtained NSPR (207, 6)\n",
      "obtained VKTX (207, 6)\n",
      "obtained GRNH (207, 6)\n",
      "obtained SNGX (207, 6)\n",
      "RSGE is missing\n",
      "obtained MRNS (207, 6)\n"
     ]
    }
   ],
   "source": [
    "# Set parameters for quotes download\n",
    "data_source = 'yahoo'\n",
    "start = \"2018-01-01\"\n",
    "end = \"2018-12-23\"\n",
    "\n",
    "# Initialize counters\n",
    "fail_count = 0\n",
    "ok_count = 0\n",
    "closing_prices = pd.DataFrame()\n",
    "\n",
    "#D ownload closing prices and stack them together\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        result = web.DataReader(ticker, data_source, start, end)\n",
    "        tmp_df = result[['Adj Close']]\n",
    "        tmp_df.columns = [ticker]\n",
    "        closing_prices = pd.concat([closing_prices,tmp_df], axis=1)\n",
    "        print (\"obtained \" + ticker + \" \" + repr(result.shape))\n",
    "        ok_count += 1\n",
    "    except:\n",
    "        print (ticker + \" is missing\")\n",
    "        fail_count += 1\n",
    "\n",
    "\n",
    "# Write to csv\n",
    "closing_prices.to_csv('./tmp/raw_stock_quotes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = pd.read_csv('./tmp/raw_stock_quotes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally, 'penny stocks' are more likely to be the object of a pump-and-dump scheme due to low liquidity and lack of analytical coverage. Penny stocks are often defined as stocks with a price less than $5.\n",
    "\n",
    "Also, we need to have at least a couple of months of data to make meaningful conclusions about the stock dynamic. \n",
    "\n",
    "Therefore, we keep only stocks that had mean price of $5 or less and that have at least 50 days of observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 366)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find stocks with mean price less or equal to $5\n",
    "mean_price = quotes.mean()\n",
    "mean_price = mean_price[mean_price <= 5]\n",
    "\n",
    "# Keep only those stocks in the database\n",
    "quotes = quotes.loc[:,mean_price.index]\n",
    "\n",
    "# Find stocks with more than 50 observations\n",
    "obs_count = quotes.count()\n",
    "obs_count = obs_count[obs_count >= 50]\n",
    "\n",
    "# Keep only those stocks in the database\n",
    "quotes = quotes.loc[:,obs_count.index]\n",
    "\n",
    "quotes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CCCL',\n",
       " 'HEME',\n",
       " 'SCYX',\n",
       " 'SGYP',\n",
       " 'RSHN',\n",
       " 'OGEN',\n",
       " 'DTEA',\n",
       " 'ISBG',\n",
       " 'LCLP',\n",
       " 'BLPG']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column values\n",
    "tickers_clean = quotes.columns.values\n",
    "\n",
    "# Remove '.1 artifact'\n",
    "tickers_clean = list(map(lambda x: x.replace(\".1\",\"\"), tickers_clean))\n",
    "tickers_clean[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Identify what stocks are mentioned in each comment/post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load a dataset scraped from /r/stocks. Although the moderators of /r/stocks do not support posting related to penny stocks, such an activity still may happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_author</th>\n",
       "      <th>com_date</th>\n",
       "      <th>com_text</th>\n",
       "      <th>post_author</th>\n",
       "      <th>post_date</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_url</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cracklinrosi</td>\n",
       "      <td>2018-10-24T02:23:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vovr</td>\n",
       "      <td>2018-10-23T22:20:35+00:00</td>\n",
       "      <td>I never bought bonds before. I need some tips ...</td>\n",
       "      <td>How can I get started with bonds?</td>\n",
       "      <td>https://old.reddit.com/r/stocks/comments/9qtr4...</td>\n",
       "      <td>/r/stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brrr69</td>\n",
       "      <td>2018-10-23T17:34:16+00:00</td>\n",
       "      <td>Apple is such a great company I would never se...</td>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:30:35+00:00</td>\n",
       "      <td>I have two Fidelity mutual funds (FSPTX and OP...</td>\n",
       "      <td>Should I sell or hold? New to the world of inv...</td>\n",
       "      <td>https://old.reddit.com/r/stocks/comments/9qr6n...</td>\n",
       "      <td>/r/stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:39:41+00:00</td>\n",
       "      <td>Okay so you invest in individual stocks. Wonde...</td>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:30:35+00:00</td>\n",
       "      <td>I have two Fidelity mutual funds (FSPTX and OP...</td>\n",
       "      <td>Should I sell or hold? New to the world of inv...</td>\n",
       "      <td>https://old.reddit.com/r/stocks/comments/9qr6n...</td>\n",
       "      <td>/r/stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brrr69</td>\n",
       "      <td>2018-10-23T17:44:28+00:00</td>\n",
       "      <td>Only companies I research and Iâ€™m confident in...</td>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:30:35+00:00</td>\n",
       "      <td>I have two Fidelity mutual funds (FSPTX and OP...</td>\n",
       "      <td>Should I sell or hold? New to the world of inv...</td>\n",
       "      <td>https://old.reddit.com/r/stocks/comments/9qr6n...</td>\n",
       "      <td>/r/stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:48:56+00:00</td>\n",
       "      <td>gotcha. I'll do some reading into that.</td>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:30:35+00:00</td>\n",
       "      <td>I have two Fidelity mutual funds (FSPTX and OP...</td>\n",
       "      <td>Should I sell or hold? New to the world of inv...</td>\n",
       "      <td>https://old.reddit.com/r/stocks/comments/9qr6n...</td>\n",
       "      <td>/r/stocks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     com_author                   com_date  \\\n",
       "0  cracklinrosi  2018-10-24T02:23:06+00:00   \n",
       "1        brrr69  2018-10-23T17:34:16+00:00   \n",
       "2  linux_rich87  2018-10-23T17:39:41+00:00   \n",
       "3        brrr69  2018-10-23T17:44:28+00:00   \n",
       "4  linux_rich87  2018-10-23T17:48:56+00:00   \n",
       "\n",
       "                                            com_text   post_author  \\\n",
       "0                                                NaN          vovr   \n",
       "1  Apple is such a great company I would never se...  linux_rich87   \n",
       "2  Okay so you invest in individual stocks. Wonde...  linux_rich87   \n",
       "3  Only companies I research and Iâ€™m confident in...  linux_rich87   \n",
       "4           gotcha. I'll do some reading into that.   linux_rich87   \n",
       "\n",
       "                   post_date  \\\n",
       "0  2018-10-23T22:20:35+00:00   \n",
       "1  2018-10-23T17:30:35+00:00   \n",
       "2  2018-10-23T17:30:35+00:00   \n",
       "3  2018-10-23T17:30:35+00:00   \n",
       "4  2018-10-23T17:30:35+00:00   \n",
       "\n",
       "                                           post_text  \\\n",
       "0  I never bought bonds before. I need some tips ...   \n",
       "1  I have two Fidelity mutual funds (FSPTX and OP...   \n",
       "2  I have two Fidelity mutual funds (FSPTX and OP...   \n",
       "3  I have two Fidelity mutual funds (FSPTX and OP...   \n",
       "4  I have two Fidelity mutual funds (FSPTX and OP...   \n",
       "\n",
       "                                          post_title  \\\n",
       "0                  How can I get started with bonds?   \n",
       "1  Should I sell or hold? New to the world of inv...   \n",
       "2  Should I sell or hold? New to the world of inv...   \n",
       "3  Should I sell or hold? New to the world of inv...   \n",
       "4  Should I sell or hold? New to the world of inv...   \n",
       "\n",
       "                                            post_url  subreddit  \n",
       "0  https://old.reddit.com/r/stocks/comments/9qtr4...  /r/stocks  \n",
       "1  https://old.reddit.com/r/stocks/comments/9qr6n...  /r/stocks  \n",
       "2  https://old.reddit.com/r/stocks/comments/9qr6n...  /r/stocks  \n",
       "3  https://old.reddit.com/r/stocks/comments/9qr6n...  /r/stocks  \n",
       "4  https://old.reddit.com/r/stocks/comments/9qr6n...  /r/stocks  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.read_csv(\"data/stocks.csv\", parse_dates=True)\n",
    "\n",
    "#Add a flag of the subreddit\n",
    "stocks['subreddit'] = '/r/stocks'\n",
    "stocks.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine datasets from all three subreddits: stocks, pennystocks, and RobinHoodPennyStocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "penny = penny.append(stocks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the shape of the resulting raw database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/r/RobinHoodPennyStocks</th>\n",
       "      <td>9477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/r/pennystocks</th>\n",
       "      <td>6390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/r/stocks</th>\n",
       "      <td>11056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         post_url\n",
       "subreddit                        \n",
       "/r/RobinHoodPennyStocks      9477\n",
       "/r/pennystocks               6390\n",
       "/r/stocks                   11056"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penny[['post_url', 'subreddit']].groupby('subreddit').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine post title, post text and comment text to identify the context\n",
    "penny['all_text'] = penny['post_title'] + penny['post_text'] + penny['com_text']\n",
    "\n",
    "# Load clean ticker names\n",
    "with open(\"./tmp/tickers_clean\", \"rb\") as fb:\n",
    "    tickers = pickle.load(fb)\n",
    "    \n",
    "# Remove $ and NASDAQ: prefixes\n",
    "penny['all_text'] = penny['all_text'].str.replace(\"$\",\" \")\n",
    "penny['all_text'] = penny['all_text'].str.replace(\"NASDAQ:\",\" \")\n",
    "\n",
    "# Create a column that flags what tickers are mentioned in the context of the thread\n",
    "penny['context'] = penny.all_text.apply(lambda x: list(set(\n",
    "                                        [value for value in str(x).split() if value in tickers]\n",
    "                                        )))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid double accounting in future NLP analysis, after identifying the context we treat original post as a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that treats each initial post as a comment. This way we adoid double accounting for posts\n",
    "# and comments\n",
    "penny['post_text'] = penny['post_title'] + penny['post_text']  #Combine original post text and title\n",
    "org_post = penny.loc[:,[\"post_author\", \"post_date\", \"post_text\", \"context\", \"post_url\", \"subreddit\"]]\n",
    "org_post.columns = [\"com_author\", \"com_date\", \"com_text\", \"context\", \"post_url\", \"subreddit\"]\n",
    "org_post['top_post'] = 1\n",
    "\n",
    "# Remove observations that do not have any comments (they will be replaced by original post)\n",
    "penny = penny.loc[penny.com_text.notna(),\\\n",
    "                  [\"com_author\", \"com_date\", \"com_text\", \"context\", \"post_url\", \"subreddit\"]]\n",
    "penny['top_post'] = 0\n",
    "\n",
    "#Combine both\n",
    "df = penny.append(other=org_post, ignore_index=True)\n",
    "df.drop_duplicates(subset = [\"com_author\", \"com_date\", \"com_text\", \"post_url\", \"subreddit\"],inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep only observations that contain some context regarding target stocks. \n",
    "\n",
    "We extract date from datetime, and save the file for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations without context\n",
    "df = df.loc[df['context'].str.len()!=0, :]\n",
    "\n",
    "#Reset index\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Exctract date\n",
    "df['com_date'] = df['com_date'].apply(lambda x: pd.to_datetime(str(x)[0:10]))\n",
    "\n",
    "df.to_csv(\"./data/scrape_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the the count of posts in the final database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/r/RobinHoodPennyStocks</th>\n",
       "      <td>3543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/r/pennystocks</th>\n",
       "      <td>2166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/r/stocks</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         com_text\n",
       "subreddit                        \n",
       "/r/RobinHoodPennyStocks      3543\n",
       "/r/pennystocks               2166\n",
       "/r/stocks                     171"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the count of unique posts\n",
    "df[['com_text', 'subreddit']].groupby('subreddit').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The analysis of the data is performed in [Analysis.ipynb](Analysis.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
