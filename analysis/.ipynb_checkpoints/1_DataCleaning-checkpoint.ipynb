{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the scraped dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import pandas_datareader.data as web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the raw scraped datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_author</th>\n",
       "      <th>com_date</th>\n",
       "      <th>com_text</th>\n",
       "      <th>post_author</th>\n",
       "      <th>post_date</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuftybigfoot</td>\n",
       "      <td>2018-10-23T00:00:33+00:00</td>\n",
       "      <td>What about Canadian traders?</td>\n",
       "      <td>Al1Ge</td>\n",
       "      <td>2018-10-22T22:47:57+00:00</td>\n",
       "      <td>If so, what platform do you trade through?</td>\n",
       "      <td>Any UK based traders?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xTheHolyGhostx</td>\n",
       "      <td>2018-10-22T13:57:59+00:00</td>\n",
       "      <td>Very nice. I plan to hold onto my shares for a...</td>\n",
       "      <td>CaptainWeee</td>\n",
       "      <td>2018-10-22T13:34:50+00:00</td>\n",
       "      <td>Wow another article dropped today about us som...</td>\n",
       "      <td>$HIPH Another article released today with us i...</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mojaverae</td>\n",
       "      <td>2018-10-22T15:44:45+00:00</td>\n",
       "      <td>Big investors Sold on the news, took profits</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smooferated</td>\n",
       "      <td>2018-10-23T03:26:20+00:00</td>\n",
       "      <td>Always sell and take profits.  Especially when...</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jarsofmarsbarsincars</td>\n",
       "      <td>2018-10-22T16:29:45+00:00</td>\n",
       "      <td>People who invested at low prices pulled their...</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             com_author                   com_date  \\\n",
       "0          Tuftybigfoot  2018-10-23T00:00:33+00:00   \n",
       "1        xTheHolyGhostx  2018-10-22T13:57:59+00:00   \n",
       "2             Mojaverae  2018-10-22T15:44:45+00:00   \n",
       "3           smooferated  2018-10-23T03:26:20+00:00   \n",
       "4  jarsofmarsbarsincars  2018-10-22T16:29:45+00:00   \n",
       "\n",
       "                                            com_text  post_author  \\\n",
       "0                       What about Canadian traders?        Al1Ge   \n",
       "1  Very nice. I plan to hold onto my shares for a...  CaptainWeee   \n",
       "2       Big investors Sold on the news, took profits  vertical006   \n",
       "3  Always sell and take profits.  Especially when...  vertical006   \n",
       "4  People who invested at low prices pulled their...  vertical006   \n",
       "\n",
       "                   post_date  \\\n",
       "0  2018-10-22T22:47:57+00:00   \n",
       "1  2018-10-22T13:34:50+00:00   \n",
       "2  2018-10-22T15:43:23+00:00   \n",
       "3  2018-10-22T15:43:23+00:00   \n",
       "4  2018-10-22T15:43:23+00:00   \n",
       "\n",
       "                                           post_text  \\\n",
       "0         If so, what platform do you trade through?   \n",
       "1  Wow another article dropped today about us som...   \n",
       "2  I picked up a few stocks months before Canada ...   \n",
       "3  I picked up a few stocks months before Canada ...   \n",
       "4  I picked up a few stocks months before Canada ...   \n",
       "\n",
       "                                          post_title  \\\n",
       "0                              Any UK based traders?   \n",
       "1  $HIPH Another article released today with us i...   \n",
       "2    What's going on with Canadian marijuana stocks?   \n",
       "3    What's going on with Canadian marijuana stocks?   \n",
       "4    What's going on with Canadian marijuana stocks?   \n",
       "\n",
       "                                            post_url  \n",
       "0  https://old.reddit.com/r/pennystocks/comments/...  \n",
       "1  https://old.reddit.com/r/pennystocks/comments/...  \n",
       "2  https://old.reddit.com/r/pennystocks/comments/...  \n",
       "3  https://old.reddit.com/r/pennystocks/comments/...  \n",
       "4  https://old.reddit.com/r/pennystocks/comments/...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penny_stock = pd.read_csv(\"data/penny_stocks.csv\", parse_dates=True)\n",
    "penny_stock.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a sample to use in the presentation\n",
    "\n",
    "penny_stock.loc[0:5,:].to_csv(\"./output/raw_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_author</th>\n",
       "      <th>com_date</th>\n",
       "      <th>com_text</th>\n",
       "      <th>post_author</th>\n",
       "      <th>post_date</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weredagabagool</td>\n",
       "      <td>2018-10-23T14:59:06+00:00</td>\n",
       "      <td>This sub is kryptonite to every single stock m...</td>\n",
       "      <td>Vigamoxx</td>\n",
       "      <td>2018-10-23T14:01:50+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFMK shooting up!!</td>\n",
       "      <td>https://old.reddit.com/r/RobinHoodPennyStocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>julbjulb</td>\n",
       "      <td>2018-10-23T14:05:06+00:00</td>\n",
       "      <td>You had to jinx it lol</td>\n",
       "      <td>Vigamoxx</td>\n",
       "      <td>2018-10-23T14:01:50+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFMK shooting up!!</td>\n",
       "      <td>https://old.reddit.com/r/RobinHoodPennyStocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vigamoxx</td>\n",
       "      <td>2018-10-23T14:06:36+00:00</td>\n",
       "      <td>Yeah I bought at $2.01 at 9:58, at 10:00 it wa...</td>\n",
       "      <td>Vigamoxx</td>\n",
       "      <td>2018-10-23T14:01:50+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFMK shooting up!!</td>\n",
       "      <td>https://old.reddit.com/r/RobinHoodPennyStocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>julbjulb</td>\n",
       "      <td>2018-10-23T14:54:27+00:00</td>\n",
       "      <td>ðŸ“ˆ gl</td>\n",
       "      <td>Vigamoxx</td>\n",
       "      <td>2018-10-23T14:01:50+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFMK shooting up!!</td>\n",
       "      <td>https://old.reddit.com/r/RobinHoodPennyStocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joesmithers</td>\n",
       "      <td>2018-10-22T23:23:10+00:00</td>\n",
       "      <td>My immediate goal is to get above $25,000 so I...</td>\n",
       "      <td>Joesmithers</td>\n",
       "      <td>2018-10-22T23:17:17+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rate my meme portfolio</td>\n",
       "      <td>https://old.reddit.com/r/RobinHoodPennyStocks/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       com_author                   com_date  \\\n",
       "0  weredagabagool  2018-10-23T14:59:06+00:00   \n",
       "1        julbjulb  2018-10-23T14:05:06+00:00   \n",
       "2        Vigamoxx  2018-10-23T14:06:36+00:00   \n",
       "3        julbjulb  2018-10-23T14:54:27+00:00   \n",
       "4     Joesmithers  2018-10-22T23:23:10+00:00   \n",
       "\n",
       "                                            com_text  post_author  \\\n",
       "0  This sub is kryptonite to every single stock m...     Vigamoxx   \n",
       "1                             You had to jinx it lol     Vigamoxx   \n",
       "2  Yeah I bought at $2.01 at 9:58, at 10:00 it wa...     Vigamoxx   \n",
       "3                                               ðŸ“ˆ gl     Vigamoxx   \n",
       "4  My immediate goal is to get above $25,000 so I...  Joesmithers   \n",
       "\n",
       "                   post_date post_text              post_title  \\\n",
       "0  2018-10-23T14:01:50+00:00       NaN      IFMK shooting up!!   \n",
       "1  2018-10-23T14:01:50+00:00       NaN      IFMK shooting up!!   \n",
       "2  2018-10-23T14:01:50+00:00       NaN      IFMK shooting up!!   \n",
       "3  2018-10-23T14:01:50+00:00       NaN      IFMK shooting up!!   \n",
       "4  2018-10-22T23:17:17+00:00       NaN  Rate my meme portfolio   \n",
       "\n",
       "                                            post_url  \n",
       "0  https://old.reddit.com/r/RobinHoodPennyStocks/...  \n",
       "1  https://old.reddit.com/r/RobinHoodPennyStocks/...  \n",
       "2  https://old.reddit.com/r/RobinHoodPennyStocks/...  \n",
       "3  https://old.reddit.com/r/RobinHoodPennyStocks/...  \n",
       "4  https://old.reddit.com/r/RobinHoodPennyStocks/...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robin = pd.read_csv(\"data/robin.csv\", parse_dates=True)\n",
    "robin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_author</th>\n",
       "      <th>com_date</th>\n",
       "      <th>com_text</th>\n",
       "      <th>post_author</th>\n",
       "      <th>post_date</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_url</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuftybigfoot</td>\n",
       "      <td>2018-10-23T00:00:33+00:00</td>\n",
       "      <td>What about Canadian traders?</td>\n",
       "      <td>Al1Ge</td>\n",
       "      <td>2018-10-22T22:47:57+00:00</td>\n",
       "      <td>If so, what platform do you trade through?</td>\n",
       "      <td>Any UK based traders?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xTheHolyGhostx</td>\n",
       "      <td>2018-10-22T13:57:59+00:00</td>\n",
       "      <td>Very nice. I plan to hold onto my shares for a...</td>\n",
       "      <td>CaptainWeee</td>\n",
       "      <td>2018-10-22T13:34:50+00:00</td>\n",
       "      <td>Wow another article dropped today about us som...</td>\n",
       "      <td>$HIPH Another article released today with us i...</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mojaverae</td>\n",
       "      <td>2018-10-22T15:44:45+00:00</td>\n",
       "      <td>Big investors Sold on the news, took profits</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smooferated</td>\n",
       "      <td>2018-10-23T03:26:20+00:00</td>\n",
       "      <td>Always sell and take profits.  Especially when...</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jarsofmarsbarsincars</td>\n",
       "      <td>2018-10-22T16:29:45+00:00</td>\n",
       "      <td>People who invested at low prices pulled their...</td>\n",
       "      <td>vertical006</td>\n",
       "      <td>2018-10-22T15:43:23+00:00</td>\n",
       "      <td>I picked up a few stocks months before Canada ...</td>\n",
       "      <td>What's going on with Canadian marijuana stocks?</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             com_author                   com_date  \\\n",
       "0          Tuftybigfoot  2018-10-23T00:00:33+00:00   \n",
       "1        xTheHolyGhostx  2018-10-22T13:57:59+00:00   \n",
       "2             Mojaverae  2018-10-22T15:44:45+00:00   \n",
       "3           smooferated  2018-10-23T03:26:20+00:00   \n",
       "4  jarsofmarsbarsincars  2018-10-22T16:29:45+00:00   \n",
       "\n",
       "                                            com_text  post_author  \\\n",
       "0                       What about Canadian traders?        Al1Ge   \n",
       "1  Very nice. I plan to hold onto my shares for a...  CaptainWeee   \n",
       "2       Big investors Sold on the news, took profits  vertical006   \n",
       "3  Always sell and take profits.  Especially when...  vertical006   \n",
       "4  People who invested at low prices pulled their...  vertical006   \n",
       "\n",
       "                   post_date  \\\n",
       "0  2018-10-22T22:47:57+00:00   \n",
       "1  2018-10-22T13:34:50+00:00   \n",
       "2  2018-10-22T15:43:23+00:00   \n",
       "3  2018-10-22T15:43:23+00:00   \n",
       "4  2018-10-22T15:43:23+00:00   \n",
       "\n",
       "                                           post_text  \\\n",
       "0         If so, what platform do you trade through?   \n",
       "1  Wow another article dropped today about us som...   \n",
       "2  I picked up a few stocks months before Canada ...   \n",
       "3  I picked up a few stocks months before Canada ...   \n",
       "4  I picked up a few stocks months before Canada ...   \n",
       "\n",
       "                                          post_title  \\\n",
       "0                              Any UK based traders?   \n",
       "1  $HIPH Another article released today with us i...   \n",
       "2    What's going on with Canadian marijuana stocks?   \n",
       "3    What's going on with Canadian marijuana stocks?   \n",
       "4    What's going on with Canadian marijuana stocks?   \n",
       "\n",
       "                                            post_url       subreddit  \n",
       "0  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks  \n",
       "1  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks  \n",
       "2  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks  \n",
       "3  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks  \n",
       "4  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set flags for the subreddit\n",
    "penny_stock['subreddit'] = '/r/pennystocks'\n",
    "robin['subreddit'] = '/r/RobinHoodPennyStocks'\n",
    "\n",
    "# Combine two datasets\n",
    "penny = penny_stock.append(robin, ignore_index=True)\n",
    "penny.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Find unique tickers mentioned in posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find unique company tickers. The result is pickled for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all textual info\n",
    "all_text = penny['post_text'] + penny['com_text'] + penny['post_title'] \n",
    "all_text = all_text.dropna().astype(str)\n",
    "all_text = \" \".join(all_text)\n",
    "\n",
    "# Get unique stocks in a form $TCKR\n",
    "set1 = re.findall(pattern='\\$[A-Z]{2,4}', string = all_text)\n",
    "set1 = list(map(lambda x: x.replace(\"$\",\"\"), set1))\n",
    "set1 = set(set1)\n",
    "\n",
    "# Get unique stocks in the form NASDAQ:TCKR\n",
    "set2 = re.findall(pattern='NASDA.:[A-Z]{2,4}', string = all_text)\n",
    "set2 = list(map(lambda x: x.replace(\"NASDAQ:\",\"\"), set1))\n",
    "set2 = set(set2)\n",
    "\n",
    "# Combine both\n",
    "tickers = [*set([*set1] + [*set2])]\n",
    "\n",
    "# Write tickers to a file\n",
    "with open('./tmp/tickers', 'wb') as fp:\n",
    "    pickle.dump(tickers, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Find unique tickers for penny stocks and download quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 'pickled' tickers extracted from the scraped dataset and try downloading stock prices data from Yahoo Finance.\n",
    "\n",
    "Some of the stocks that are traded on non-US exchanges may have additional suffixes to the ticker on Yahoo Finance. In this case this code will not obtain the stock quotes and we drop observations. It can be manually or semi-atudomatically fixed in the future research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tmp/tickers', 'rb') as fp:\n",
    "    tickers = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This code takes a while to run. You can use the csv file below instead of downloading quotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for quotes download\n",
    "data_source = 'yahoo'\n",
    "start = \"2018-01-01\"\n",
    "end = \"2018-12-23\"\n",
    "\n",
    "# Initialize counters\n",
    "fail_count = 0\n",
    "ok_count = 0\n",
    "closing_prices = pd.DataFrame()\n",
    "\n",
    "#D ownload closing prices and stack them together\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        result = web.DataReader(ticker, data_source, start, end)\n",
    "        tmp_df = result[['Adj Close']]\n",
    "        tmp_df.columns = [ticker]\n",
    "        closing_prices = pd.concat([closing_prices,tmp_df], axis=1)\n",
    "        print (\"obtained \" + ticker + \" \" + repr(result.shape))\n",
    "        ok_count += 1\n",
    "    except:\n",
    "        print (ticker + \" is missing\")\n",
    "        fail_count += 1\n",
    "\n",
    "\n",
    "# Write to csv\n",
    "closing_prices.to_csv('./tmp/raw_stock_quotes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = pd.read_csv('./tmp/raw_stock_quotes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally, 'penny stocks' are more likely to be the object of a pump-and-dump scheme due to low liquidity and lack of analytical coverage. Penny stocks are often defined as stocks with a price less than $5.\n",
    "\n",
    "Also, we need to have at least a couple of months of data to make meaningful conclusions about the stock dynamic. \n",
    "\n",
    "Therefore, we keep only stocks that had mean price of $5 or less and that have at least 50 days of observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 175)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find stocks with mean price less or equal to $5\n",
    "mean_price = quotes.mean()\n",
    "mean_price = mean_price[mean_price <= 5]\n",
    "\n",
    "# Keep only those stocks in the database\n",
    "quotes = quotes.loc[:,mean_price.index]\n",
    "\n",
    "# Find stocks with more than 50 observations\n",
    "obs_count = quotes.count()\n",
    "obs_count = obs_count[obs_count >= 50]\n",
    "\n",
    "# Keep only those stocks in the database\n",
    "quotes = quotes.loc[:,obs_count.index]\n",
    "\n",
    "quotes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column values\n",
    "tickers_clean = quotes.columns.values\n",
    "\n",
    "\n",
    "# Pickle\n",
    "with open(\"./tmp/tickers_clean\", \"wb\") as fb:\n",
    "    pickle.dump(tickers_clean, fb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Identify what stocks are mentioned in each comment/post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load a dataset scraped from /r/stocks. Although the moderators of /r/stocks do not support posting related to penny stocks, such an activity still may happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_author</th>\n",
       "      <th>com_date</th>\n",
       "      <th>com_text</th>\n",
       "      <th>post_author</th>\n",
       "      <th>post_date</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_url</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cracklinrosi</td>\n",
       "      <td>2018-10-24T02:23:06+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vovr</td>\n",
       "      <td>2018-10-23T22:20:35+00:00</td>\n",
       "      <td>I never bought bonds before. I need some tips ...</td>\n",
       "      <td>How can I get started with bonds?</td>\n",
       "      <td>https://old.reddit.com/r/stocks/comments/9qtr4...</td>\n",
       "      <td>/r/stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brrr69</td>\n",
       "      <td>2018-10-23T17:34:16+00:00</td>\n",
       "      <td>Apple is such a great company I would never se...</td>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:30:35+00:00</td>\n",
       "      <td>I have two Fidelity mutual funds (FSPTX and OP...</td>\n",
       "      <td>Should I sell or hold? New to the world of inv...</td>\n",
       "      <td>https://old.reddit.com/r/stocks/comments/9qr6n...</td>\n",
       "      <td>/r/stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:39:41+00:00</td>\n",
       "      <td>Okay so you invest in individual stocks. Wonde...</td>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:30:35+00:00</td>\n",
       "      <td>I have two Fidelity mutual funds (FSPTX and OP...</td>\n",
       "      <td>Should I sell or hold? New to the world of inv...</td>\n",
       "      <td>https://old.reddit.com/r/stocks/comments/9qr6n...</td>\n",
       "      <td>/r/stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brrr69</td>\n",
       "      <td>2018-10-23T17:44:28+00:00</td>\n",
       "      <td>Only companies I research and Iâ€™m confident in...</td>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:30:35+00:00</td>\n",
       "      <td>I have two Fidelity mutual funds (FSPTX and OP...</td>\n",
       "      <td>Should I sell or hold? New to the world of inv...</td>\n",
       "      <td>https://old.reddit.com/r/stocks/comments/9qr6n...</td>\n",
       "      <td>/r/stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:48:56+00:00</td>\n",
       "      <td>gotcha. I'll do some reading into that.</td>\n",
       "      <td>linux_rich87</td>\n",
       "      <td>2018-10-23T17:30:35+00:00</td>\n",
       "      <td>I have two Fidelity mutual funds (FSPTX and OP...</td>\n",
       "      <td>Should I sell or hold? New to the world of inv...</td>\n",
       "      <td>https://old.reddit.com/r/stocks/comments/9qr6n...</td>\n",
       "      <td>/r/stocks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     com_author                   com_date  \\\n",
       "0  cracklinrosi  2018-10-24T02:23:06+00:00   \n",
       "1        brrr69  2018-10-23T17:34:16+00:00   \n",
       "2  linux_rich87  2018-10-23T17:39:41+00:00   \n",
       "3        brrr69  2018-10-23T17:44:28+00:00   \n",
       "4  linux_rich87  2018-10-23T17:48:56+00:00   \n",
       "\n",
       "                                            com_text   post_author  \\\n",
       "0                                                NaN          vovr   \n",
       "1  Apple is such a great company I would never se...  linux_rich87   \n",
       "2  Okay so you invest in individual stocks. Wonde...  linux_rich87   \n",
       "3  Only companies I research and Iâ€™m confident in...  linux_rich87   \n",
       "4           gotcha. I'll do some reading into that.   linux_rich87   \n",
       "\n",
       "                   post_date  \\\n",
       "0  2018-10-23T22:20:35+00:00   \n",
       "1  2018-10-23T17:30:35+00:00   \n",
       "2  2018-10-23T17:30:35+00:00   \n",
       "3  2018-10-23T17:30:35+00:00   \n",
       "4  2018-10-23T17:30:35+00:00   \n",
       "\n",
       "                                           post_text  \\\n",
       "0  I never bought bonds before. I need some tips ...   \n",
       "1  I have two Fidelity mutual funds (FSPTX and OP...   \n",
       "2  I have two Fidelity mutual funds (FSPTX and OP...   \n",
       "3  I have two Fidelity mutual funds (FSPTX and OP...   \n",
       "4  I have two Fidelity mutual funds (FSPTX and OP...   \n",
       "\n",
       "                                          post_title  \\\n",
       "0                  How can I get started with bonds?   \n",
       "1  Should I sell or hold? New to the world of inv...   \n",
       "2  Should I sell or hold? New to the world of inv...   \n",
       "3  Should I sell or hold? New to the world of inv...   \n",
       "4  Should I sell or hold? New to the world of inv...   \n",
       "\n",
       "                                            post_url  subreddit  \n",
       "0  https://old.reddit.com/r/stocks/comments/9qtr4...  /r/stocks  \n",
       "1  https://old.reddit.com/r/stocks/comments/9qr6n...  /r/stocks  \n",
       "2  https://old.reddit.com/r/stocks/comments/9qr6n...  /r/stocks  \n",
       "3  https://old.reddit.com/r/stocks/comments/9qr6n...  /r/stocks  \n",
       "4  https://old.reddit.com/r/stocks/comments/9qr6n...  /r/stocks  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.read_csv(\"data/stocks.csv\", parse_dates=True)\n",
    "\n",
    "#Add a flag of the subreddit\n",
    "stocks['subreddit'] = '/r/stocks'\n",
    "stocks.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine datasets from all three subreddits: stocks, pennystocks, and RobinHoodPennyStocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "penny = penny.append(stocks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the shape of the resulting raw database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/r/RobinHoodPennyStocks</th>\n",
       "      <td>9477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/r/pennystocks</th>\n",
       "      <td>6390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/r/stocks</th>\n",
       "      <td>11056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         post_url\n",
       "subreddit                        \n",
       "/r/RobinHoodPennyStocks      9477\n",
       "/r/pennystocks               6390\n",
       "/r/stocks                   11056"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penny[['post_url', 'subreddit']].groupby('subreddit').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cleaned tickers\n",
    "with open (\"./tmp/tickers_clean\", \"rb\") as fb:\n",
    "    tickers = pickle.load(fb)\n",
    "\n",
    "\n",
    "# Combine post title, post text and comment text to identify the context\n",
    "penny['all_text'] = penny['post_title'] + penny['post_text'] + penny['com_text']\n",
    "\n",
    "    \n",
    "# Remove $ and NASDAQ: prefixes\n",
    "penny['all_text'] = penny['all_text'].str.replace(\"$\",\" \")\n",
    "penny['all_text'] = penny['all_text'].str.replace(\"NASDAQ:\",\" \")\n",
    "\n",
    "# Create a column that flags what tickers are mentioned in the context of the thread\n",
    "penny['context'] = penny.all_text.apply(lambda x: \"|\".join(list(set(\n",
    "                                        [value for value in str(x).split() if value in tickers]\n",
    "                                        ))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid double accounting in future NLP analysis, after identifying the context we treat original post as a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that treats each initial post as a comment. This way we adoid double accounting for posts\n",
    "# and comments\n",
    "penny['post_text'] = penny['post_title'] + penny['post_text']  #Combine original post text and title\n",
    "org_post = penny.loc[:,[\"post_author\", \"post_date\", \"post_text\", \"context\", \"post_url\", \"subreddit\"]]\n",
    "org_post.columns = [\"com_author\", \"com_date\", \"com_text\", \"context\", \"post_url\", \"subreddit\"]\n",
    "org_post['top_post'] = 1\n",
    "\n",
    "# Remove observations that do not have any comments (they will be replaced by original post)\n",
    "penny = penny.loc[penny.com_text.notna(),\\\n",
    "                  [\"com_author\", \"com_date\", \"com_text\", \"context\", \"post_url\", \"subreddit\"]]\n",
    "penny['top_post'] = 0\n",
    "\n",
    "#Combine both\n",
    "df = penny.append(other=org_post, ignore_index=True)\n",
    "df.drop_duplicates(subset = [\"com_author\", \"com_date\", \"com_text\", \"post_url\", \"subreddit\"],inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep only observations that contain some context regarding target stocks. \n",
    "\n",
    "We extract date from datetime, and save the file for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_author</th>\n",
       "      <th>com_date</th>\n",
       "      <th>com_text</th>\n",
       "      <th>context</th>\n",
       "      <th>post_url</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>top_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xTheHolyGhostx</td>\n",
       "      <td>2018-10-22</td>\n",
       "      <td>Very nice. I plan to hold onto my shares for a...</td>\n",
       "      <td>HIPH</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CaptainWeee</td>\n",
       "      <td>2018-10-22</td>\n",
       "      <td>Yup same brother!!!</td>\n",
       "      <td>HIPH</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdamCaveRoberts</td>\n",
       "      <td>2018-10-22</td>\n",
       "      <td>I first entered at 0.04 then left at 0.07. Kin...</td>\n",
       "      <td>HIPH</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BongRips4Jezus</td>\n",
       "      <td>2018-10-22</td>\n",
       "      <td>Now would be the time, itâ€™s dipping hard as fu...</td>\n",
       "      <td>HIPH</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CaptainWeee</td>\n",
       "      <td>2018-10-22</td>\n",
       "      <td>Yup entire sector should move back up tomorrow...</td>\n",
       "      <td>HIPH</td>\n",
       "      <td>https://old.reddit.com/r/pennystocks/comments/...</td>\n",
       "      <td>/r/pennystocks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        com_author   com_date  \\\n",
       "0   xTheHolyGhostx 2018-10-22   \n",
       "1      CaptainWeee 2018-10-22   \n",
       "2  AdamCaveRoberts 2018-10-22   \n",
       "3   BongRips4Jezus 2018-10-22   \n",
       "4      CaptainWeee 2018-10-22   \n",
       "\n",
       "                                            com_text context  \\\n",
       "0  Very nice. I plan to hold onto my shares for a...    HIPH   \n",
       "1                                Yup same brother!!!    HIPH   \n",
       "2  I first entered at 0.04 then left at 0.07. Kin...    HIPH   \n",
       "3  Now would be the time, itâ€™s dipping hard as fu...    HIPH   \n",
       "4  Yup entire sector should move back up tomorrow...    HIPH   \n",
       "\n",
       "                                            post_url       subreddit  top_post  \n",
       "0  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks         0  \n",
       "1  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks         0  \n",
       "2  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks         0  \n",
       "3  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks         0  \n",
       "4  https://old.reddit.com/r/pennystocks/comments/...  /r/pennystocks         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop observations without context\n",
    "df = df.loc[df['context'].str.len()!=0, :]\n",
    "\n",
    "#Reset index\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Exctract date\n",
    "df['com_date'] = df['com_date'].apply(lambda x: pd.to_datetime(str(x)[0:10]))\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for future use\n",
    "df.to_csv(\"./data/scrape_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the the count of posts in the final database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/r/RobinHoodPennyStocks</th>\n",
       "      <td>3991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/r/pennystocks</th>\n",
       "      <td>2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/r/stocks</th>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         com_text\n",
       "subreddit                        \n",
       "/r/RobinHoodPennyStocks      3991\n",
       "/r/pennystocks               2256\n",
       "/r/stocks                     219"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the count of unique posts\n",
    "df[['com_text', 'subreddit']].groupby('subreddit').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stock quotes and sraped data are merged into one data frame in [2_Compile.ipynb](2_Compile.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
